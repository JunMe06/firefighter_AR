{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline # plot in cell\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# for svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "feature_names = ['mean_x', 'mean_y', 'mean_z', \n",
    "                'rms_x', 'rms_y', 'rms_z',\n",
    "                'std_x', 'std_y', 'std_z',\n",
    "                'var_x', 'var_y', 'var_z',\n",
    "                'med_x', 'med_y', 'med_z',\n",
    "                'min_x', 'min_y', 'min_z',\n",
    "                'max_x', 'max_y', 'max_z',\n",
    "                'pearsonr_xy', 'pearsonr_yz', 'pearsonr_zx',\n",
    "                'mad_x', 'mad_y', 'mad_z']\n",
    "\n",
    "target_names = ['Standing', 'Walking normal', 'Jumping', \n",
    "                'Sit chair', 'Stairs up', 'Stairs down']\n",
    "              \n",
    "\n",
    "def featuresFromBuffer(at):\n",
    "    feat = np.zeros(27)    # return array float([ 0.,  0.,  0.,  0., ....., 0.])\n",
    "                            # a vector of 21 features from each window\n",
    "    x = np.array(at.iloc[:,0], dtype=np.float64)   \n",
    "    y = np.array(at.iloc[:,1], dtype=np.float64)   \n",
    "    z = np.array(at.iloc[:,2], dtype=np.float64)  \n",
    "   \n",
    "    \n",
    "   # Average value in signal buffer for all three acceleration components (1 each)    \n",
    "    means = [np.mean(i) for i in [x, y, z]]\n",
    "    feat[0:3] = means\n",
    "    \n",
    "    # RMS value in signal buffer for all three acceleration components (1 each)\n",
    "    rms = [np.sqrt(np.mean(i**2)) for i in [x, y, z]]\n",
    "    feat[3:6] = rms\n",
    "    \n",
    "    # Standard deviation\n",
    "    std = [np.std(i) for i in [x, y, z]]\n",
    "    feat[6:9] = std\n",
    "    \n",
    "    # Variance\n",
    "    var = [np.var(i) for i in [x, y, z]]\n",
    "    feat[9:12] = var\n",
    "    \n",
    "    # Median\n",
    "    med = [np.median(i) for i in [x, y, z]]\n",
    "    feat[12:15] = med\n",
    "    \n",
    "    # Range\n",
    "    Range1 = [ np.amin(i) for i in [x, y, z]]    \n",
    "    feat[15:18] = Range1\n",
    "    Range2 = [ np.amax(i) for i in [x, y, z]]    \n",
    "    feat[18:21] = Range2\n",
    "    \n",
    "    # Median Absolute Deviation\n",
    "    mad = [stats.median_absolute_deviation(i) for i in [x, y, z]]   \n",
    "    feat[21:24] = mad\n",
    "\n",
    "    return feat  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STD', 'Unnamed: 1', 'Unnamed: 2', 'WAL', 'Unnamed: 4', 'Unnamed: 5',\n",
       "       'JUM', 'Unnamed: 7', 'Unnamed: 8', 'STU', 'Unnamed: 10', 'Unnamed: 11',\n",
       "       'STN', 'Unnamed: 13', 'Unnamed: 14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(23781, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "dt = pd.read_excel (r'D:\\\\Matlab\\\\data.xlsx')\n",
    "dt.columns\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23151\n",
      "23780\n",
      "7190\n",
      "4843\n",
      "4746\n"
     ]
    }
   ],
   "source": [
    "Standing = dt[['STD', 'Unnamed: 1', 'Unnamed: 2']] \n",
    "# Delete columns contain missing value (NaN or not value)\n",
    "Standing = Standing.dropna()\n",
    "# Create index (start from 1) in first column\n",
    "Standing.index = pd.RangeIndex(len(Standing.index))\n",
    "# Drop the first row ((Xoá hàng x,y,z))\n",
    "Standing = Standing.drop(0)\n",
    "\n",
    "Walking_normal = dt[['WAL', 'Unnamed: 4', 'Unnamed: 5']] \n",
    "Walking_normal = Walking_normal.dropna()\n",
    "Walking_normal.index = pd.RangeIndex(len(Walking_normal.index))\n",
    "Walking_normal = Walking_normal.drop(0)\n",
    "\n",
    "Jumping = dt[['JUM', 'Unnamed: 7', 'Unnamed: 8']] \n",
    "Jumping = Jumping.dropna()\n",
    "Jumping.index = pd.RangeIndex(len(Jumping.index))\n",
    "Jumping = Jumping.drop(0)\n",
    "\n",
    "Stairs_up = dt[['STU', 'Unnamed: 10', 'Unnamed: 11']] \n",
    "Stairs_up = Stairs_up.dropna()\n",
    "Stairs_up.index = pd.RangeIndex(len(Stairs_up.index)) \n",
    "Stairs_up = Stairs_up.drop(0)\n",
    "    \n",
    "Stairs_down = dt[['STN', 'Unnamed: 13', 'Unnamed: 14']] \n",
    "Stairs_down = Stairs_down.dropna()\n",
    "Stairs_down.index = pd.RangeIndex(len(Stairs_down.index))\n",
    "Stairs_down = Stairs_down.drop(0)\n",
    "\n",
    "print (len(Standing))\n",
    "print (len (Walking_normal))\n",
    "print (len (Jumping))\n",
    "print (len (Stairs_up))\n",
    "print (len (Stairs_down))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_stand_train:  2315\n",
      "X_stand_test:  1541\n",
      "X_walk_train:  2378\n",
      "X_walk_test:  1583\n",
      "X_jump_train:  719\n",
      "X_jump_test:  477\n",
      "X_stairUp_train:  485\n",
      "X_stairUp_test:  321\n",
      "X_stairDown_train:  475\n",
      "X_stairDown_test:  314\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to 2 parts: Train (60%) - Test (40%)\\n\",\n",
    "\n",
    "window_size = 16\n",
    "stride = 6 #step\n",
    "\n",
    "# range (start, stop, step)\n",
    "X_stand_train = [Standing[i:i+window_size] for i in range(0, int(len(Standing)*0.6), stride)] \n",
    "X_stand_test = [Standing[i:i+window_size] for i in range(int(len(Standing)*0.6), len(Standing), stride) \n",
    "                                            if i+window_size<=len(Standing)]\n",
    "\n",
    "X_walk_train = [Walking_normal[i:i+window_size] for i in range(0, int(len(Walking_normal)*0.6), stride)]\n",
    "X_walk_test = [Walking_normal[i:i+window_size] for i in range(int(len(Walking_normal)*0.6), len(Walking_normal),                                stride) if i+window_size<=len(Walking_normal)]\n",
    "\n",
    "X_jump_train = [Jumping[i:i+window_size] for i in range(0, int(len(Jumping)*0.6), stride)]\n",
    "X_jump_test = [Jumping[i:i+window_size] for i in range(int(len(Jumping)*0.6), len(Jumping), stride) \n",
    "                                            if i+window_size<=len(Jumping)]\n",
    "\n",
    "X_stairUp_train = [Stairs_up[i:i+window_size] for i in range(0, int(len(Stairs_up)*0.6), stride)] \n",
    "X_stairUp_test = [Stairs_up[i:i+window_size] for i in range(int(len(Stairs_up)*0.6), len(Stairs_up), stride) \n",
    "                                                if i+window_size<=len(Stairs_up)]\n",
    "\n",
    "X_stairDown_train = [Stairs_down[i:i+window_size] for i in range(0, int(len(Stairs_down)*0.6), stride)] \n",
    "X_stairDown_test = [Stairs_down[i:i+window_size] for i in range(int(len(Stairs_down)*0.6), len(Stairs_down),                                                        stride) if i+window_size<=len(Stairs_down)]\n",
    "\n",
    "print ('X_stand_train: ', len(X_stand_train))\n",
    "print ('X_stand_test: ', len(X_stand_test))\n",
    "\n",
    "print ('X_walk_train: ', len(X_walk_train))\n",
    "print ('X_walk_test: ', len(X_walk_test))\n",
    "\n",
    "print ('X_jump_train: ', len (X_jump_train))\n",
    "print ('X_jump_test: ', len (X_jump_test))\n",
    "\n",
    "print ('X_stairUp_train: ', len (X_stairUp_train))\n",
    "print ('X_stairUp_test: ', len (X_stairUp_test))\n",
    "\n",
    "print ('X_stairDown_train: ', len (X_stairDown_train))\n",
    "print ('X_stairDown_test: ', len (X_stairDown_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-data length:  6372\n",
      "train-label length:  6372\n",
      "test-data length:  4236\n",
      "test-label length:  4236\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "for acts in X_stand_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(0)\n",
    "    \n",
    "for acts in X_walk_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(1)\n",
    "\n",
    "for acts in X_jump_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(2)\n",
    "\n",
    "for acts in X_stairUp_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(3)\n",
    "\n",
    "for acts in X_stairDown_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(4)\n",
    "\n",
    "print('train-data length: ', len(train_data) )\n",
    "print('train-label length: ', len(train_label) )\n",
    "#print(train_label)\n",
    "      \n",
    "# For TEST\n",
    "\n",
    "for acts in X_stand_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(0)\n",
    "\n",
    "for acts in X_walk_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(1)\n",
    "\n",
    "for acts in X_jump_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(2)\n",
    "\n",
    "for acts in X_stairUp_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(3)\n",
    "\n",
    "for acts in X_stairDown_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(4)\n",
    "\n",
    "print('test-data length: ', len(test_data))\n",
    "print('test-label length: ', len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6372"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4236"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo mảng features \n",
    "train_features = []\n",
    "test_features = []\n",
    "for action in train_data:\n",
    "    feat = featuresFromBuffer(action)\n",
    "    train_features.append(feat)  \n",
    "\n",
    "for action in test_data:\n",
    "    feat = featuresFromBuffer(action)\n",
    "    test_features.append(feat)\n",
    "\n",
    "len(train_features)\n",
    "len(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Decision Tree:\n"
     ]
    }
   ],
   "source": [
    "# beginning of classification:\n",
    "#https://www.kaggle.com/beagle01/prediction-with-gradient-boosting-classifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "print(\"Gradient Boosting Decision Tree:\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf1 = GradientBoostingClassifier(learning_rate=0.05,max_depth=3,n_estimators=100).fit(train_features, train_label)\n",
    "#format: pass score in {:.3f}\n",
    "print('Accuracy of GBDT classifier on training set: {:.3f}'\n",
    "     .format(clf1.score(train_features, train_label)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.3f}'\n",
    "     .format(clf1.score(test_features, test_label)))\n",
    "\n",
    "\n",
    "print(\"\\n\\nDecision Tree:\") \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_decision_tree  # Nên giữ file adspy_ cùng thư mục vs các file python to use adspy_.\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=4).fit(train_features, train_label)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.3f}'.format(clf2.score(train_features, train_label)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.3f}'\n",
    ".format(clf2.score(test_features, test_label)))\n",
    "\n",
    "\n",
    "print(\"\\n\\nSVM:\")\n",
    "clf3 = SVC(C=100, gamma='scale').fit(train_features, train_label)\n",
    "print(\"Accuracy on training set: {:.2f}\".format(clf3.score(train_features, train_label)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(clf3.score(test_features, test_label)))\n",
    "\n",
    "\n",
    "print('\\n\\n Random Forests: ')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf4 = RandomForestClassifier(n_estimators=200, random_state=0).fit(train_features, train_label)\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.3f}'\n",
    "     .format(clf4.score(train_features, train_label)))\n",
    "print('Accuracy of RF classifier on test set: {:.3f}'\n",
    "     .format(clf4.score(test_features, test_label)))\n",
    "\n",
    "\n",
    "print('\\n\\n KNeighbor: ')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance').fit(train_features, train_label)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(train_features, train_label)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(test_features, test_label)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n KNeighbor: ')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance').fit(train_features, train_label)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(train_features, train_label)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(test_features, test_label)))\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "y_pred = knn.predict(test_features)\n",
    "f1_score(test_label, y_pred, average='macro')\n",
    "recall_score(test_label, y_pred, average='macro')\n",
    "precision_score(test_label, y_pred, average='macro')\n",
    "\n",
    "f1_score(test_label, y_pred, average='micro')\n",
    "recall_score(test_label, y_pred, average='micro')\n",
    "precision_score(test_label, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from sklearn import neighbors\n",
    "import graphviz \n",
    "from sklearn.tree import export_graphviz\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "def plot_labelled_scatter(X, y, class_labels): \n",
    "    num_labels = len(class_labels)\n",
    "    print(num_labels)\n",
    "\n",
    "    # create a mesh (lưới) to plot the boundaries (đường biên)\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1   # min & max for feature 1 ((column 0)) \n",
    "                    # X[row, column]\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1   # min & max for feature 2 (column 1)\n",
    "    \n",
    "    colors = ['#fdb915', '#00AAFF', '#FF00AA', #'#acbf69', '#ff0000', \n",
    "              '#10a674', '#c04e01'] \n",
    "    cmap = ListedColormap(colors) \n",
    "    \n",
    "   # Generate a colormap index based on discrete intervals\n",
    "    norm = BoundaryNorm(numpy.arange(0, num_labels+1, 1), ncolors=num_labels) \n",
    "    \n",
    "    plt.figure(figsize=(15, 12))  # độ dài row & column của \n",
    "    \n",
    "    plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=cmap, norm=norm, alpha=0.3, lw=1)\n",
    "                #edgecolor='black'\n",
    "    \n",
    "    # Create array h[] chứa chú thích behaviors & colors tương ứng\n",
    "    h = []\n",
    "    for c in range(0, num_labels):\n",
    "        # tạo chú thích = mpatches.Patch\n",
    "        h.append(mpatches.Patch(color=colors[c], label=class_labels[c])) \n",
    "    plt.legend(handles=h, fontsize = 'x-small') # show ghi chu\n",
    "    \n",
    "    plt.xlabel('Đặc trưng 1')\n",
    "    plt.ylabel('Đặc trưng 2')\n",
    "    plt.title('Dữ liệu t-SNE')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "X_visual = train_features\n",
    "y_visual = np.array(train_label, dtype=np.uint8) \n",
    "\n",
    "n_samples = 300\n",
    "n_components = 2  # dimension\n",
    "perplexity = 30.0 # number of NEAREST NEIGHBORS that used in other MALIFOLD LEARNING algorithm (value: 5-50)\n",
    "RS = 1000   \n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# fit X_visual into embedding space in low-dimensional space and return  array (n_samples, n_components) \n",
    "X_tsne = TSNE(random_state=RS, n_components=2, perplexity=30.0, learning_rate=300.0 ).fit_transform(X_visual)\n",
    "#  , n_components=2, perplexity=30.0, learning_rate=300.0             \n",
    "plot_labelled_scatter(X_tsne, y_visual,['Standing','Walking normal','Jumping', \n",
    "                                        'Stairs up','Stairs down'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bita6c16f8bd0f8458dae0b3c3b36181794"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
