{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      \\n     # SMA\\n    sma = sma_unit(x)+ sma_unit(y) + sma_unit(z)\\n    feat[30] = sma\\n    \\n    #tilt angel\\n    #TA = [(np.arccos(i))/9.8 for i in z]\\n    #feat[31] = TA\\n\\n    # Covariance \\n    # find out covariance with respect  rows (axis = 0)\\n    cov_xy = np.stack((x, y), axis = 0)\\n    cov_yz = np.stack((y, z), axis = 0)\\n    cov_zx = np.stack((z, x), axis = 0)\\n \\n    corr_xy =  (np.cov(cov_xy))/(np.std(x)*np.std(y))\\n    feat[] = corr_xy\\n    corr_yz =  (np.cov(cov_yz))/(np.std(y)*np.std(z))\\n    feat[] = corr_yz\\n    corr_zx =  (np.cov(cov_zx))/(np.std(z)*np.std(x))\\n    feat[] = corr_zx\\n    \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline # plot in cell\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# for svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "feature_names = ['mean_x', 'mean_y', 'mean_z', \n",
    "                'rms_x', 'rms_y', 'rms_z',\n",
    "                'std_x', 'std_y', 'std_z',\n",
    "                'var_x', 'var_y', 'var_z',\n",
    "                'med_x', 'med_y', 'med_z',\n",
    "                'min_x', 'min_y', 'min_z',\n",
    "                'max_x', 'max_y', 'max_z',\n",
    "                'pearsonr_xy', 'pearsonr_yz', 'pearsonr_zx',\n",
    "                'mad_x', 'mad_y', 'mad_z',\n",
    "                'iqr_x', 'iqr_y','iqr_z']\n",
    "\n",
    "target_names = ['Standing', 'Walking normal', 'Jumping', \n",
    "                'Sit chair', 'Stairs up', 'Stairs down']\n",
    "                #'Car Step in', 'Car Step out',\n",
    "                #'Back sitting chair', 'Fall front kness lying', \n",
    "                #'Fall forward lying','Sideward lying']\n",
    "            \n",
    "### TIME domain \n",
    "## mean, the standard deviation, the median, the correlation, the tilt angle (TA)\n",
    "\n",
    "def featuresFromBuffer(at):\n",
    "    feat = np.zeros(30)    # return array float([ 0.,  0.,  0.,  0., ....., 0.])\n",
    "                            # a vector of 21 features from each window\n",
    "    x = np.array(at.iloc[:,0], dtype=np.float64)   # get value all row, column = 0\n",
    "    y = np.array(at.iloc[:,1], dtype=np.float64)   # \n",
    "    z = np.array(at.iloc[:,2], dtype=np.float64)   # \n",
    "   \n",
    "    \n",
    "    # Average value in signal buffer for all three acceleration components (1 each)    \n",
    "    means = [np.mean(i) for i in [x, y, z]]\n",
    "    feat[0:3] = means\n",
    "    \n",
    "    # RMS value in signal buffer for all three acceleration components (1 each)\n",
    "    rms = [np.sqrt(np.mean(i**2)) for i in [x, y, z]]\n",
    "    feat[3:6] = rms\n",
    "    \n",
    "    # Standard deviation\n",
    "    std = [np.std(i) for i in [x, y, z]]\n",
    "    feat[6:9] = std\n",
    "    \n",
    "    # Variance\n",
    "    var = [np.var(i) for i in [x, y, z]]\n",
    "    feat[9:12] = var\n",
    "    \n",
    "    # Median\n",
    "    med = [np.median(i) for i in [x, y, z]]\n",
    "    feat[12:15] = med\n",
    "    \n",
    "    # Range\n",
    "    Range1 = [ np.amin(i) for i in [x, y, z]]    \n",
    "    feat[15:18] = Range1\n",
    "    Range2 = [ np.amax(i) for i in [x, y, z]]    \n",
    "    feat[18:21] = Range2\n",
    "    \n",
    "    # Pearsonr   \n",
    "    x_pd = pd.Series(x)\n",
    "    y_pd = pd.Series(y)\n",
    "    z_pd = pd.Series(z)\n",
    "    Pearsonr_xy = x_pd.corr(y_pd)\n",
    "    feat[21] = Pearsonr_xy\n",
    "    Pearsonr_yz = y_pd.corr(z_pd)\n",
    "    feat[22] = Pearsonr_yz\n",
    "    Pearsonr_zx = z_pd.corr(x_pd)\n",
    "    feat[23] = Pearsonr_zx\n",
    "    \n",
    "    # Median Absolute Deviation\n",
    "    mad = [stats.median_absolute_deviation(i) for i in [x, y, z]]   \n",
    "    feat[24:27] = mad\n",
    "    \n",
    "    # Interquartile range (khoảng tứ nhị phân)\n",
    "    iqr = [stats.iqr(i) for i in [x, y, z]]\n",
    "    feat[27:30] = iqr\n",
    "    return feat\n",
    "'''      \n",
    "     # SMA\n",
    "    sma = sma_unit(x)+ sma_unit(y) + sma_unit(z)\n",
    "    feat[30] = sma\n",
    "    \n",
    "    #tilt angel\n",
    "    #TA = [(np.arccos(i))/9.8 for i in z]\n",
    "    #feat[31] = TA\n",
    "\n",
    "    # Covariance \n",
    "    # find out covariance with respect  rows (axis = 0)\n",
    "    cov_xy = np.stack((x, y), axis = 0)\n",
    "    cov_yz = np.stack((y, z), axis = 0)\n",
    "    cov_zx = np.stack((z, x), axis = 0)\n",
    " \n",
    "    corr_xy =  (np.cov(cov_xy))/(np.std(x)*np.std(y))\n",
    "    feat[] = corr_xy\n",
    "    corr_yz =  (np.cov(cov_yz))/(np.std(y)*np.std(z))\n",
    "    feat[] = corr_yz\n",
    "    corr_zx =  (np.cov(cov_zx))/(np.std(z)*np.std(x))\n",
    "    feat[] = corr_zx\n",
    "    \n",
    "'''    \n",
    "\n",
    "### Frequency Domain\n",
    "##  the frequency energy, the frequency entropy, and the wavelet energy,\n",
    "    \n",
    "def energy(value_fft):\n",
    "    en = 0.0\n",
    "    for i in value_fft:\n",
    "        en = en + i**2\n",
    "    final_energy = en/len(value_fft)\n",
    "    return final_energy\n",
    "\n",
    "def featuresFrequency(at):\n",
    "    feat_fft = np.zeros(30)\n",
    "    x = np.array(at[:,0], dtype=np.float64)   # get value all row, column = 0\n",
    "    y = np.array(at[:,1], dtype=np.float64)   # \n",
    "    z = np.array(at[:,2], dtype=np.float64)\n",
    "    \n",
    "    # Ennergy\n",
    "    Energy = [energy(i) for i in [x, y, z]]\n",
    "    feat_fft[0:3] = Energy\n",
    "    \n",
    "    # skew\n",
    "    skew = [stats.skew(i) for i in [x, y, z]]   \n",
    "    feat_fft[3:6] = skew\n",
    "    \n",
    "    kurtosis = [stats.kurtosis(i) for i in [x, y, z]]   \n",
    "    feat_fft[6:9] = kurtosis\n",
    "    \n",
    "    return feat_fft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def entropy(labels):\n",
    "    prob_dict = {x:labels.count(x)/len(labels) for x in labels}\n",
    "    probs = np.array(list(prob_dict.values()))\n",
    "\n",
    "    return - probs.dot(np.log2(probs))\n",
    "labels = [0, 0, 1, 1]\n",
    "i = entropy(labels)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Standing', 'Unnamed: 1', 'Unnamed: 2', 'Walking normal', 'Unnamed: 4',\n",
       "       'Unnamed: 5', 'Jumping', 'Unnamed: 7', 'Unnamed: 8', 'Jogging',\n",
       "       'Unnamed: 10', 'Unnamed: 11', 'Sit chair', 'Unnamed: 13', 'Unnamed: 14',\n",
       "       'Stairs up', 'Unnamed: 16', 'Unnamed: 17', 'Stairs down', 'Unnamed: 19',\n",
       "       'Unnamed: 20', 'Car Step-in', 'Unnamed: 22', 'Unnamed: 23',\n",
       "       'Car Step-out', 'Unnamed: 25', 'Unnamed: 26', 'Back sitting chair',\n",
       "       'Unnamed: 28', 'Unnamed: 29', 'Fall front knees lying', 'Unnamed: 31',\n",
       "       'Unnamed: 32', 'Fall forward lying', 'Unnamed: 34', 'Unnamed: 35',\n",
       "       'Sideward lying', 'Unnamed: 37', 'Unnamed: 38'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28939, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "dt = pd.read_excel (r'F:\\\\Program\\\\OneDrive\\\\KHOÁ LUẬN 2020\\\\acc_data.xlsx')\n",
    "dt.columns\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28938\n",
      "26158\n",
      "7909\n",
      "2794\n",
      "3137\n",
      "3160\n"
     ]
    }
   ],
   "source": [
    "Standing = dt[['Standing', 'Unnamed: 1', 'Unnamed: 2']] \n",
    "# Delete columns contain missing value (NaN or not value)\n",
    "Standing = Standing.dropna()\n",
    "# Create index (start from 1) in first column\n",
    "Standing.index = pd.RangeIndex(len(Standing.index))\n",
    "# Drop the first row ((Xoá hàng x,y,z))\n",
    "Standing = Standing.drop(0)\n",
    "\n",
    "Walking_normal = dt[['Walking normal', 'Unnamed: 4', 'Unnamed: 5']] \n",
    "Walking_normal = Walking_normal.dropna()\n",
    "Walking_normal.index = pd.RangeIndex(len(Walking_normal.index))\n",
    "Walking_normal = Walking_normal.drop(0)\n",
    "\n",
    "Jumping = dt[['Jumping', 'Unnamed: 7', 'Unnamed: 8']] \n",
    "Jumping = Jumping.dropna()\n",
    "Jumping.index = pd.RangeIndex(len(Jumping.index))\n",
    "Jumping = Jumping.drop(0)\n",
    "\n",
    "Sit_chair = dt[['Sit chair', 'Unnamed: 13', 'Unnamed: 14']] \n",
    "Sit_chair = Sit_chair.dropna()\n",
    "Sit_chair.index = pd.RangeIndex(len(Sit_chair.index)) \n",
    "Sit_chair = Sit_chair.drop(0)\n",
    "\n",
    "Stairs_up = dt[['Stairs up', 'Unnamed: 16', 'Unnamed: 17']] \n",
    "Stairs_up = Stairs_up.dropna()\n",
    "Stairs_up.index = pd.RangeIndex(len(Stairs_up.index)) \n",
    "Stairs_up = Stairs_up.drop(0)\n",
    "    \n",
    "Stairs_down = dt[['Stairs down', 'Unnamed: 19', 'Unnamed: 20']] \n",
    "Stairs_down = Stairs_down.dropna()\n",
    "Stairs_down.index = pd.RangeIndex(len(Stairs_down.index))\n",
    "Stairs_down = Stairs_down.drop(0)\n",
    "\n",
    "print (len(Standing))\n",
    "print (len (Walking_normal))\n",
    "print (len (Jumping))\n",
    "print (len (Sit_chair))\n",
    "print (len (Stairs_up))\n",
    "print (len (Stairs_down))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cell for FFT\n",
    "Standing_fft = np.fft.fft(Standing)\n",
    "Walking_normal_fft = np.fft.fft(Walking_normal)\n",
    "Jumping_fft = np.fft.fft(Jumping)\n",
    "Sit_chair_fft = np.fft.fft(Sit_chair)\n",
    "Stairs_up_fft = np.fft.fft(Stairs_up)\n",
    "Stairs_down_fft = np.fft.fft(Stairs_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_stand_fft_train:  2894\n",
      "X_stand_fft_test:  1928\n",
      "X_walk_fft_train:  2616\n",
      "X_walk_fft_test:  1743\n",
      "X_jump_fft_train:  791\n",
      "X_jump_fft_test:  526\n",
      "X_sit_fft_train:  280\n",
      "X_sit_fft_test:  185\n",
      "X_stairUp_fft_train:  314\n",
      "X_stairUp_fft_test:  208\n",
      "X_stairDown_fft_train:  316\n",
      "X_stairDown_fft_test:  210\n"
     ]
    }
   ],
   "source": [
    "### Cell for FFT\n",
    "window_size = 10\n",
    "stride = 6 #step\n",
    "\n",
    "# range (start, stop, step)\n",
    "X_stand_fft_train = [Standing_fft[i:i+window_size] for i in range(0, int(len(Standing_fft)*0.6), stride)] \n",
    "X_stand_fft_test = [Standing_fft[i:i+window_size] for i in range(int(len(Standing_fft)*0.6), len(Standing_fft), stride) \n",
    "                                            if i+window_size<=len(Standing_fft)]\n",
    "X_walk_fft_train = [Walking_normal_fft[i:i+window_size] for i in range(0, int(len(Walking_normal_fft)*0.6), stride)]\n",
    "X_walk_fft_test = [Walking_normal_fft[i:i+window_size] for i in range(int(len(Walking_normal_fft)*0.6), len(Walking_normal_fft),                                stride) if i+window_size<=len(Walking_normal)]\n",
    "\n",
    "X_jump_fft_train = [Jumping_fft[i:i+window_size] for i in range(0, int(len(Jumping_fft)*0.6), stride)]\n",
    "X_jump_fft_test = [Jumping_fft[i:i+window_size] for i in range(int(len(Jumping_fft)*0.6), len(Jumping_fft), stride) \n",
    "                                            if i+window_size<=len(Jumping_fft)]\n",
    "\n",
    "X_sit_fft_train = [Sit_chair_fft[i:i+window_size] for i in range(0, int(len(Sit_chair_fft)*0.6), stride)] \n",
    "X_sit_fft_test = [Sit_chair_fft[i:i+window_size] for i in range(int(len(Sit_chair_fft)*0.6), len(Sit_chair_fft), stride) \n",
    "                                            if i+window_size<=len(Sit_chair_fft)]\n",
    "\n",
    "X_stairUp_fft_train = [Stairs_up_fft[i:i+window_size] for i in range(0, int(len(Stairs_up_fft)*0.6), stride)] \n",
    "X_stairUp_fft_test = [Stairs_up_fft[i:i+window_size] for i in range(int(len(Stairs_up_fft)*0.6), len(Stairs_up_fft), stride) \n",
    "                                                if i+window_size<=len(Stairs_up_fft)]\n",
    "\n",
    "X_stairDown_fft_train = [Stairs_down_fft[i:i+window_size] for i in range(0, int(len(Stairs_down_fft)*0.6), stride)] \n",
    "X_stairDown_fft_test = [Stairs_down_fft[i:i+window_size] for i in range(int(len(Stairs_down_fft)*0.6), len(Stairs_down_fft), \n",
    "                                                            stride) if i+window_size<=len(Stairs_down_fft)]\n",
    "\n",
    "print ('X_stand_fft_train: ', len(X_stand_fft_train))\n",
    "print ('X_stand_fft_test: ', len(X_stand_fft_test))\n",
    "\n",
    "print ('X_walk_fft_train: ', len(X_walk_fft_train))\n",
    "print ('X_walk_fft_test: ', len(X_walk_fft_test))\n",
    "\n",
    "print ('X_jump_fft_train: ', len (X_jump_fft_train))\n",
    "print ('X_jump_fft_test: ', len (X_jump_fft_test))\n",
    "\n",
    "\n",
    "print ('X_sit_fft_train: ', len (X_sit_fft_train))\n",
    "print ('X_sit_fft_test: ', len (X_sit_fft_test))\n",
    "\n",
    "print ('X_stairUp_fft_train: ', len (X_stairUp_fft_train))\n",
    "print ('X_stairUp_fft_test: ', len (X_stairUp_fft_test))\n",
    "\n",
    "print ('X_stairDown_fft_train: ', len (X_stairDown_fft_train))\n",
    "print ('X_stairDown_fft_test: ', len (X_stairDown_fft_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_fft_data length:  7211\n",
      "train_fft_label length:  7211\n",
      "test_fft-data length:  4800\n",
      "test_fft-label length:  4800\n"
     ]
    }
   ],
   "source": [
    "## FFT Frequency\n",
    "\n",
    "train_fft_data = []\n",
    "train_fft_label = []\n",
    "\n",
    "test_fft_data = []\n",
    "test_fft_label = []\n",
    "\n",
    "for acts in X_stand_fft_train:\n",
    "    train_fft_data.append(acts)\n",
    "    train_fft_label.append(0)\n",
    "    \n",
    "for acts in X_walk_fft_train:\n",
    "    train_fft_data.append(acts)\n",
    "    train_fft_label.append(1)\n",
    "\n",
    "for acts in X_jump_fft_train:\n",
    "    train_fft_data.append(acts)\n",
    "    train_fft_label.append(2)\n",
    "\n",
    "for acts in X_sit_fft_train:\n",
    "    train_fft_data.append(acts)\n",
    "    train_fft_label.append(3)\n",
    "\n",
    "for acts in X_stairUp_fft_train:\n",
    "    train_fft_data.append(acts)\n",
    "    train_fft_label.append(4)\n",
    "\n",
    "for acts in X_stairDown_fft_train:\n",
    "    train_fft_data.append(acts)\n",
    "    train_fft_label.append(5)\n",
    "\n",
    "print('train_fft_data length: ', len(train_fft_data) )\n",
    "print('train_fft_label length: ', len(train_fft_label))\n",
    "\n",
    "# For TEST\n",
    "\n",
    "for acts in X_stand_fft_test:\n",
    "    test_fft_data.append(acts)\n",
    "    test_fft_label.append(0)\n",
    "\n",
    "for acts in X_walk_fft_test:\n",
    "    test_fft_data.append(acts)\n",
    "    test_fft_label.append(1)\n",
    "\n",
    "for acts in X_jump_fft_test:\n",
    "    test_fft_data.append(acts)\n",
    "    test_fft_label.append(2)\n",
    "\n",
    "for acts in X_sit_fft_test:\n",
    "    test_fft_data.append(acts)\n",
    "    test_fft_label.append(3)\n",
    "\n",
    "for acts in X_stairUp_fft_test:\n",
    "    test_fft_data.append(acts)\n",
    "    test_fft_label.append(4)\n",
    "\n",
    "for acts in X_stairDown_fft_test:\n",
    "    test_fft_data.append(acts)\n",
    "    test_fft_label.append(5)\n",
    "\n",
    "\n",
    "print('test_fft-data length: ', len(test_fft_data))\n",
    "print('test_fft-label length: ', len(test_fft_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_stand_train:  2894\n",
      "X_stand_test:  1928\n",
      "X_walk_train:  2616\n",
      "X_walk_test:  1743\n",
      "X_jump_train:  791\n",
      "X_jump_test:  526\n",
      "X_sit_train:  280\n",
      "X_sit_test:  185\n",
      "X_stairUp_train:  314\n",
      "X_stairUp_test:  208\n",
      "X_stairDown_train:  316\n",
      "X_stairDown_test:  210\n"
     ]
    }
   ],
   "source": [
    "# TIME\n",
    "# Split dataset to 2 parts: Train (60%) - Test (40%)\\n\",\n",
    "\n",
    "window_size = 10\n",
    "stride = 6 #step\n",
    "\n",
    "# range (start, stop, step)\n",
    "X_stand_train = [Standing[i:i+window_size] for i in range(0, int(len(Standing)*0.6), stride)] \n",
    "X_stand_test = [Standing[i:i+window_size] for i in range(int(len(Standing)*0.6), len(Standing), stride) \n",
    "                                            if i+window_size<=len(Standing)]\n",
    "\n",
    "X_walk_train = [Walking_normal[i:i+window_size] for i in range(0, int(len(Walking_normal)*0.6), stride)]\n",
    "X_walk_test = [Walking_normal[i:i+window_size] for i in range(int(len(Walking_normal)*0.6), len(Walking_normal),                                stride) if i+window_size<=len(Walking_normal)]\n",
    "\n",
    "X_jump_train = [Jumping[i:i+window_size] for i in range(0, int(len(Jumping)*0.6), stride)]\n",
    "X_jump_test = [Jumping[i:i+window_size] for i in range(int(len(Jumping)*0.6), len(Jumping), stride) \n",
    "                                            if i+window_size<=len(Jumping)]\n",
    "\n",
    "X_sit_train = [Sit_chair[i:i+window_size] for i in range(0, int(len(Sit_chair)*0.6), stride)] \n",
    "X_sit_test = [Sit_chair[i:i+window_size] for i in range(int(len(Sit_chair)*0.6), len(Sit_chair), stride) \n",
    "                                            if i+window_size<=len(Sit_chair)]\n",
    "\n",
    "X_stairUp_train = [Stairs_up[i:i+window_size] for i in range(0, int(len(Stairs_up)*0.6), stride)] \n",
    "X_stairUp_test = [Stairs_up[i:i+window_size] for i in range(int(len(Stairs_up)*0.6), len(Stairs_up), stride) \n",
    "                                                if i+window_size<=len(Stairs_up)]\n",
    "\n",
    "X_stairDown_train = [Stairs_down[i:i+window_size] for i in range(0, int(len(Stairs_down)*0.6), stride)] \n",
    "X_stairDown_test = [Stairs_down[i:i+window_size] for i in range(int(len(Stairs_down)*0.6), len(Stairs_down), \n",
    "                                                            stride) if i+window_size<=len(Stairs_down)]\n",
    "\n",
    "print ('X_stand_train: ', len(X_stand_train))\n",
    "print ('X_stand_test: ', len(X_stand_test))\n",
    "\n",
    "print ('X_walk_train: ', len(X_walk_train))\n",
    "print ('X_walk_test: ', len(X_walk_test))\n",
    "\n",
    "print ('X_jump_train: ', len (X_jump_train))\n",
    "print ('X_jump_test: ', len (X_jump_test))\n",
    "\n",
    "\n",
    "print ('X_sit_train: ', len (X_sit_train))\n",
    "print ('X_sit_test: ', len (X_sit_test))\n",
    "\n",
    "print ('X_stairUp_train: ', len (X_stairUp_train))\n",
    "print ('X_stairUp_test: ', len (X_stairUp_test))\n",
    "\n",
    "print ('X_stairDown_train: ', len (X_stairDown_train))\n",
    "print ('X_stairDown_test: ', len (X_stairDown_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-data length:  7211\n",
      "train-label length:  7211\n",
      "test-data length:  4800\n",
      "test-label length:  4800\n"
     ]
    }
   ],
   "source": [
    "### Time Domain\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "for acts in X_stand_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(0)\n",
    "    \n",
    "for acts in X_walk_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(1)\n",
    "\n",
    "for acts in X_jump_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(2)\n",
    "\n",
    "for acts in X_sit_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(3)\n",
    "\n",
    "for acts in X_stairUp_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(4)\n",
    "\n",
    "for acts in X_stairDown_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(5)\n",
    "\n",
    "print('train-data length: ', len(train_data) )\n",
    "print('train-label length: ', len(train_label) )\n",
    "#print(train_label)\n",
    "      \n",
    "# For TEST\n",
    "\n",
    "for acts in X_stand_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(0)\n",
    "\n",
    "for acts in X_walk_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(1)\n",
    "\n",
    "for acts in X_jump_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(2)\n",
    "\n",
    "for acts in X_sit_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(3)\n",
    "\n",
    "for acts in X_stairUp_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(4)\n",
    "\n",
    "for acts in X_stairDown_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(5)\n",
    "\n",
    "\n",
    "print('test-data length: ', len(test_data))\n",
    "print('test-label length: ', len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features array for time domain\n",
    "train_time_features = []\n",
    "test_time_features = []\n",
    "for action in train_data:\n",
    "    feat_time = featuresFromBuffer(action)\n",
    "    train_time_features.append(feat_time)  \n",
    "\n",
    "for action in test_data:\n",
    "    feat_time = featuresFromBuffer(action)\n",
    "    #print(feat)\n",
    "    test_time_features.append(feat_time)\n",
    "    #print(test_features)\n",
    "\n",
    "#print (train_features)\n",
    "len(train_time_features)\n",
    "len(test_time_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:126: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:127: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:128: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7211"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4800"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features array for FFT\n",
    "\n",
    "train_fft_features = []\n",
    "test_fft_features = []\n",
    "for action in train_fft_data:\n",
    "    feat_fft = featuresFrequency(action)\n",
    "    train_fft_features.append(feat_fft)  \n",
    "\n",
    "for action in test_fft_data:\n",
    "    feat_fft = featuresFrequency(action)\n",
    "    #print(feat)\n",
    "    test_fft_features.append(feat_fft)\n",
    "    #print(test_features)\n",
    "\n",
    "len(train_fft_features)\n",
    "len(test_fft_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14422\n",
      "14422\n",
      "9600\n",
      "9600\n"
     ]
    }
   ],
   "source": [
    "train_features = train_time_features + train_fft_features\n",
    "print(len(train_features))\n",
    "\n",
    "train_labels = train_label + train_fft_label\n",
    "print(len(train_labels))\n",
    "\n",
    "test_features = test_time_features + test_fft_features\n",
    "print(len(test_features))\n",
    "\n",
    "test_labels = test_label + test_fft_label\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Decision Tree:\n"
     ]
    }
   ],
   "source": [
    "# beginning of classification:\n",
    "#https://www.kaggle.com/beagle01/prediction-with-gradient-boosting-classifier\n",
    "\n",
    "#clf.fit(list(X_train),Y_train)\n",
    "\n",
    "print(\"Gradient Boosting Decision Tree:\")\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf1 = GradientBoostingClassifier(learning_rate=0.05,max_depth=3,n_estimators=100).fit(train_features, train_labels)\n",
    "#format: pass score in {:.3f}\n",
    "print('Accuracy of GBDT classifier on training set: {:.3f}'\n",
    "     .format(clf1.score(train_features, train_labels)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.3f}'\n",
    "     .format(clf1.score(test_features, test_labels)))\n",
    "\n",
    "\n",
    "print(\"\\n\\nDecision Tree:\") \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_decision_tree  # Nên giữ file adspy_ cùng thư mục vs các file python to use adspy_.\n",
    "\n",
    "clf2 = DecisionTreeClassifier(max_depth=4).fit(train_features, train_labels)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.3f}'.format(clf2.score(train_features, train_labels)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.3f}'\n",
    ".format(clf2.score(test_features, test_labels)))\n",
    "\n",
    "\n",
    "print(\"\\n\\nSVM:\")\n",
    "clf3 = SVC(C=100, gamma='scale').fit(train_features, train_labels)\n",
    "print(\"Accuracy on training set: {:.2f}\".format(clf3.score(train_features, train_labels)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(clf3.score(test_features, test_labels)))\n",
    "\n",
    "\n",
    "print('\\n\\n Random Forests: ')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf4 = RandomForestClassifier(n_estimators=200, random_state=0).fit(train_features, train_labels)\n",
    "\n",
    "print('Accuracy of RF classifier on training set: {:.3f}'\n",
    "     .format(clf4.score(train_features, train_labels)))\n",
    "print('Accuracy of RF classifier on test set: {:.3f}'\n",
    "     .format(clf4.score(test_features, test_labels)))\n",
    "\n",
    "\n",
    "print('\\n\\n KNeighbor: ')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance').fit(train_features, train_labels)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(train_features, train_labels)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(test_features, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bita6c16f8bd0f8458dae0b3c3b36181794"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
