{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline # plot in cell\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# for svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "feature_names = ['mean_x', 'mean_y', 'mean_z', \n",
    "                'rms_x', 'rms_y', 'rms_z',\n",
    "                'std_x', 'std_y', 'std_z',\n",
    "                'var_x', 'var_y', 'var_z',\n",
    "                'med_x', 'med_y', 'med_z',\n",
    "                'min_x', 'min_y', 'min_z',\n",
    "                'max_x', 'max_y', 'max_z']\n",
    "\n",
    "target_names = ['Standing', 'Walking normal', 'Jumping', \n",
    "                'Jogging', \n",
    "                'Sit chair', 'Stairs up', 'Stairs down']\n",
    "                #'Car Step in', 'Car Step out',\n",
    "                #'Back sitting chair', 'Fall front kness lying', \n",
    "                #'Fall forward lying','Sideward lying']\n",
    "\n",
    "def featuresFromBuffer(at):\n",
    "    feat = np.zeros(21)\n",
    "    x = np.array(at.iloc[:,0], dtype=np.float64) \n",
    "    y = np.array(at.iloc[:,1], dtype=np.float64)\n",
    "    z = np.array(at.iloc[:,2], dtype=np.float64)\n",
    "    \n",
    "    # Average value in signal buffer \n",
    "    means = [np.mean(i) for i in [x, y, z]]\n",
    "    feat[0:3] = means\n",
    "    \n",
    "    # RMS value in signal buffer \n",
    "    rms = [np.sqrt(np.mean(i**2)) for i in [x, y, z]]\n",
    "    feat[3:6] = rms\n",
    "    \n",
    "    # Standard deviation\n",
    "    std = [np.std(i) for i in [x, y, z]]\n",
    "    feat[6:9] = std\n",
    "  \n",
    "    # Variance\n",
    "    var = [np.var(i) for i in [x, y, z]]\n",
    "    feat[9:12] = var\n",
    "    \n",
    "    # Median\n",
    "    med = [np.median(i) for i in [x, y, z]]\n",
    "    feat[12:15] = med\n",
    "       \n",
    "    # Range\n",
    "    Range1 = [ np.amin(i) for i in [x, y, z]]   \n",
    "    feat[15:18] = Range1\n",
    "    Range2 = [ np.amax(i) for i in [x, y, z]]    \n",
    "    feat[18:21] = Range2\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Standing', 'Unnamed: 1', 'Unnamed: 2', 'Walking normal', 'Unnamed: 4',\n",
       "       'Unnamed: 5', 'Jumping', 'Unnamed: 7', 'Unnamed: 8', 'Jogging',\n",
       "       'Unnamed: 10', 'Unnamed: 11', 'Sit chair', 'Unnamed: 13', 'Unnamed: 14',\n",
       "       'Stairs up', 'Unnamed: 16', 'Unnamed: 17', 'Stairs down', 'Unnamed: 19',\n",
       "       'Unnamed: 20', 'Car Step-in', 'Unnamed: 22', 'Unnamed: 23',\n",
       "       'Car Step-out', 'Unnamed: 25', 'Unnamed: 26', 'Back sitting chair',\n",
       "       'Unnamed: 28', 'Unnamed: 29', 'Fall front knees lying', 'Unnamed: 31',\n",
       "       'Unnamed: 32', 'Fall forward lying', 'Unnamed: 34', 'Unnamed: 35',\n",
       "       'Sideward lying', 'Unnamed: 37', 'Unnamed: 38'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(28939, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "dt = pd.read_excel (r'F:\\\\Program\\\\OneDrive\\\\KHOÁ LUẬN 2020\\\\acc_data.xlsx')\n",
    "dt.columns\n",
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28938\n",
      "26158\n",
      "7909\n",
      "7903\n",
      "2794\n",
      "3137\n",
      "3160\n"
     ]
    }
   ],
   "source": [
    "Standing = dt[['Standing', 'Unnamed: 1', 'Unnamed: 2']] \n",
    "# Delete columns contain missing value (NaN or not value)\n",
    "Standing = Standing.dropna()\n",
    "# Create index (start from 1) in first column\n",
    "Standing.index = pd.RangeIndex(len(Standing.index))\n",
    "# Drop the first row ((Xoá hàng x,y,z))\n",
    "Standing = Standing.drop(0)\n",
    "\n",
    "Walking_normal = dt[['Walking normal', 'Unnamed: 4', 'Unnamed: 5']] \n",
    "Walking_normal = Walking_normal.dropna()\n",
    "Walking_normal.index = pd.RangeIndex(len(Walking_normal.index))\n",
    "Walking_normal = Walking_normal.drop(0)\n",
    "\n",
    "Jumping = dt[['Jumping', 'Unnamed: 7', 'Unnamed: 8']] \n",
    "Jumping = Jumping.dropna()\n",
    "Jumping.index = pd.RangeIndex(len(Jumping.index))\n",
    "Jumping = Jumping.drop(0)\n",
    "\n",
    "Jogging = dt[['Jogging', 'Unnamed: 10', 'Unnamed: 11']] \n",
    "Jogging = Jogging.dropna()\n",
    "Jogging.index = pd.RangeIndex(len(Jogging.index))\n",
    "Jogging = Jogging.drop(0)\n",
    "\n",
    "Sit_chair = dt[['Sit chair', 'Unnamed: 13', 'Unnamed: 14']] \n",
    "Sit_chair = Sit_chair.dropna()\n",
    "Sit_chair.index = pd.RangeIndex(len(Sit_chair.index)) \n",
    "Sit_chair = Sit_chair.drop(0)\n",
    "\n",
    "Stairs_up = dt[['Stairs up', 'Unnamed: 16', 'Unnamed: 17']] \n",
    "Stairs_up = Stairs_up.dropna()\n",
    "Stairs_up.index = pd.RangeIndex(len(Stairs_up.index)) \n",
    "Stairs_up = Stairs_up.drop(0)\n",
    "    \n",
    "Stairs_down = dt[['Stairs down', 'Unnamed: 19', 'Unnamed: 20']] \n",
    "Stairs_down = Stairs_down.dropna()\n",
    "Stairs_down.index = pd.RangeIndex(len(Stairs_down.index))\n",
    "Stairs_down = Stairs_down.drop(0)\n",
    "\n",
    "print (len(Standing))\n",
    "print (len (Walking_normal))\n",
    "print (len (Jumping))\n",
    "print (len (Jogging))\n",
    "print (len (Sit_chair))\n",
    "print (len (Stairs_up))\n",
    "print (len (Stairs_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_stand_train:  2894\n",
      "X_stand_test:  1927\n",
      "X_walk_train:  2616\n",
      "X_walk_test:  1742\n",
      "X_jump_train:  791\n",
      "X_jump_test:  525\n",
      "X_jog_train:  791\n",
      "X_jog_test:  525\n",
      "X_jump_train:  791\n",
      "X_jump_test:  525\n",
      "X_sit_train:  280\n",
      "X_sit_test:  184\n",
      "X_stairUp_train:  314\n",
      "X_stairUp_test:  207\n",
      "X_stairDown_train:  316\n",
      "X_stairDown_test:  209\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to 2 parts: Train (60%) - Test (40%)\\n\",\n",
    "\n",
    "window_size = 16\n",
    "stride = 6 #step\n",
    "\n",
    "# range (start, stop, step)\n",
    "X_stand_train = [Standing[i:i+window_size] for i in range(0, int(len(Standing)*0.6), stride)] \n",
    "X_stand_test = [Standing[i:i+window_size] for i in range(int(len(Standing)*0.6), len(Standing), stride) \n",
    "                                            if i+window_size<=len(Standing)]\n",
    "\n",
    "X_walk_train = [Walking_normal[i:i+window_size] for i in range(0, int(len(Walking_normal)*0.6), stride)]\n",
    "X_walk_test = [Walking_normal[i:i+window_size] for i in range(int(len(Walking_normal)*0.6), len(Walking_normal),                                stride) if i+window_size<=len(Walking_normal)]\n",
    "\n",
    "X_jump_train = [Jumping[i:i+window_size] for i in range(0, int(len(Jumping)*0.6), stride)]\n",
    "X_jump_test = [Jumping[i:i+window_size] for i in range(int(len(Jumping)*0.6), len(Jumping), stride) \n",
    "                                            if i+window_size<=len(Jumping)]\n",
    "\n",
    "X_jog_train = [Jogging[i:i+window_size] for i in range(0, int(len(Jogging)*0.6), stride)] \n",
    "X_jog_test = [Jogging[i:i+window_size] for i in range(int(len(Jogging)*0.6), len(Jogging), stride) \n",
    "                                        if i+window_size<=len(Jogging)]\n",
    "X_sit_train = [Sit_chair[i:i+window_size] for i in range(0, int(len(Sit_chair)*0.6), stride)] \n",
    "X_sit_test = [Sit_chair[i:i+window_size] for i in range(int(len(Sit_chair)*0.6), len(Sit_chair), stride) \n",
    "                                            if i+window_size<=len(Sit_chair)]\n",
    "\n",
    "X_stairUp_train = [Stairs_up[i:i+window_size] for i in range(0, int(len(Stairs_up)*0.6), stride)] \n",
    "X_stairUp_test = [Stairs_up[i:i+window_size] for i in range(int(len(Stairs_up)*0.6), len(Stairs_up), stride) \n",
    "                                                if i+window_size<=len(Stairs_up)]\n",
    "\n",
    "X_stairDown_train = [Stairs_down[i:i+window_size] for i in range(0, int(len(Stairs_down)*0.6), stride)] \n",
    "X_stairDown_test = [Stairs_down[i:i+window_size] for i in range(int(len(Stairs_down)*0.6), len(Stairs_down),                                                        stride) if i+window_size<=len(Stairs_down)]\n",
    "\n",
    "print ('X_stand_train: ', len(X_stand_train))\n",
    "print ('X_stand_test: ', len(X_stand_test))\n",
    "\n",
    "print ('X_walk_train: ', len(X_walk_train))\n",
    "print ('X_walk_test: ', len(X_walk_test))\n",
    "\n",
    "print ('X_jump_train: ', len (X_jump_train))\n",
    "print ('X_jump_test: ', len (X_jump_test))\n",
    "\n",
    "print ('X_jog_train: ', len (X_jog_train))\n",
    "print ('X_jog_test: ', len (X_jog_test))\n",
    "\n",
    "print ('X_jump_train: ', len (X_jump_train))\n",
    "print ('X_jump_test: ', len (X_jump_test))\n",
    "\n",
    "print ('X_sit_train: ', len (X_sit_train))\n",
    "print ('X_sit_test: ', len (X_sit_test))\n",
    "\n",
    "print ('X_stairUp_train: ', len (X_stairUp_train))\n",
    "print ('X_stairUp_test: ', len (X_stairUp_test))\n",
    "\n",
    "print ('X_stairDown_train: ', len (X_stairDown_train))\n",
    "print ('X_stairDown_test: ', len (X_stairDown_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-data length:  8002\n",
      "train-label length:  8002\n",
      "test-data length:  5319\n",
      "test-label length:  5319\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "for acts in X_stand_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(0)\n",
    "    \n",
    "for acts in X_walk_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(1)\n",
    "\n",
    "for acts in X_jump_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(2)\n",
    "\n",
    "for acts in X_jog_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(3)\n",
    "\n",
    "for acts in X_sit_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(3)\n",
    "\n",
    "for acts in X_stairUp_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(4)\n",
    "\n",
    "for acts in X_stairDown_train:\n",
    "    train_data.append(acts)\n",
    "    train_label.append(5)\n",
    "\n",
    "print('train-data length: ', len(train_data) )\n",
    "print('train-label length: ', len(train_label) )\n",
    "#print(train_label)\n",
    "      \n",
    "# For TEST\n",
    "\n",
    "for acts in X_stand_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(0)\n",
    "\n",
    "for acts in X_walk_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(1)\n",
    "\n",
    "for acts in X_jump_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(2)\n",
    "\n",
    "for acts in X_jog_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(3)\n",
    "\n",
    "for acts in X_sit_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(4)\n",
    "\n",
    "for acts in X_stairUp_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(5)\n",
    "\n",
    "for acts in X_stairDown_test:\n",
    "    test_data.append(acts)\n",
    "    test_label.append(6)\n",
    "\n",
    "print('test-data length: ', len(test_data))\n",
    "print('test-label length: ', len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tạo mảng features \n",
    "train_features = []\n",
    "test_features = []\n",
    "for action in train_data:\n",
    "    feat = featuresFromBuffer(action)\n",
    "    train_features.append(feat)  \n",
    "\n",
    "for action in test_data:\n",
    "    feat = featuresFromBuffer(action)\n",
    "    #print(feat)\n",
    "    test_features.append(feat)\n",
    "    #print(test_features)\n",
    "\n",
    "#print (train_features)\n",
    "len(train_features)\n",
    "len(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearch\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist = {\"max_depth\": [3, None],                  #distribution\n",
    "              \"n_estimators\":[50,100,200,300,400,500],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "forest_random = RandomizedSearchCV( estimator=RandomForestClassifier( random_state=0 ),\n",
    "                                    param_distributions=param_dist,\n",
    "                                    cv=3,              #CV\n",
    "                                    n_iter=1944,          #interation num\n",
    "                                    scoring=\"accuracy\", #metrics\n",
    "                                    n_jobs=1,           #num of core\n",
    "                                    verbose=0,          \n",
    "                                    random_state=1)\n",
    "\n",
    "forest_random.fit(train_features, train_label)\n",
    "forest_random_best = forest_random.best_estimator_ #best estimator\n",
    "print(\"Best Model Parameter: \",forest_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhaustive Grid Search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [50, 100,150 200,250, 300, 500, 800]\n",
    "max_depth = [4,5,6,7,8, 15]\n",
    "min_samples_split = [2,3, 5,8, 10, 15]\n",
    "min_samples_leaf = [1, 2,3,4, 5,6, 10] \n",
    "\n",
    "forest = RandomForestClassifier(random_state = 1)\n",
    "\n",
    "hyperGrid = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "grid = GridSearchCV(forest, hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = grid.fit(train_features, train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run with value vua tim đc\n",
    "forestOpt = RandomForestClassifier(random_state = 1, max_depth = 15,     n_estimators = 500, min_samples_split = 2, min_samples_leaf = 1)\n",
    "                                   \n",
    "modelOpt = forestOpt.fit(train_features, train_label)\n",
    "y_pred = modelOpt.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
